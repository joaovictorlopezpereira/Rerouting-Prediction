{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f89b774b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Headers\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sbn\n",
    "import ast\n",
    "import random\n",
    "random.seed(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3d47a1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports the dataset from a csv file\n",
    "dataset = pd.read_csv(\"train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33b4ce4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plots some of the dataset's information\n",
    "dataset.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30551511",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drops unwanted columns\n",
    "dataset = dataset.drop(columns=['tr_attempts'])\n",
    "dataset = dataset.drop(columns=['tr_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb7735e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removes observations with empty data\n",
    "dataset.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c30c4036",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cuts the dataset to a fraction of its size\n",
    "def cut_dataset(dataset, factor=1):\n",
    "\tdataset_temp = dataset.drop_duplicates(keep='first')\n",
    "\treturn dataset_temp.sample(frac=factor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fb2666b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Balances the dataset by cutting the larger class\n",
    "def balance_dataset(dataset, target_name, factor=1.0):\n",
    "\tdataset_temp = dataset.drop_duplicates(keep='first')\n",
    "\tclass_0 = dataset_temp[dataset_temp[target_name] == 0]\n",
    "\tclass_1 = dataset_temp[dataset_temp[target_name] == 1]\n",
    "\t\n",
    "\tif len(class_0) > len(class_1):\n",
    "\t\tclass_1 = class_1.sample(int(len(class_1) * factor))\n",
    "\t\tclass_0 = class_0.sample(len(class_1))\n",
    "\telse:\n",
    "\t\tclass_0 = class_0.sample(int(len(class_0) * factor))\n",
    "\t\tclass_1 = class_1.sample(len(class_0))\n",
    "\n",
    "\treturn pd.concat([class_0, class_1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26c68fdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cuts pairs\n",
    "def cut_pairs(dataset, factor=1.0):\n",
    "    pairs = dataset[['tr_src', 'tr_dst']].drop_duplicates()\n",
    "    sampled_pairs = pairs.sample(frac=factor)\n",
    "    display(len(sampled_pairs))\n",
    "    filtered_dataset = dataset.merge(sampled_pairs, on=['tr_src', 'tr_dst'], how='inner')\n",
    "    return filtered_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae6a41c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trims excess data pairwise\n",
    "def trim_excess_data_pairwise(dataset, k=1):\n",
    "\tprocessed_dataset = pd.DataFrame({})\n",
    "\tpairs = dataset[['tr_src', 'tr_dst']].drop_duplicates()\n",
    "\n",
    "\tfor _, pair in pairs.iterrows():\n",
    "\t\tpair_samples = dataset.loc[(dataset['tr_src'] == pair['tr_src']) & (dataset['tr_dst'] == pair['tr_dst'])]\n",
    "\t\tpair_samples = pair_samples.sort_values(by='seconds_since_start')\n",
    "\t\tn = len(pair_samples)\n",
    "\t\tif n < k:\n",
    "\t\t\tprocessed_dataset = pd.concat([processed_dataset, pair_samples])\n",
    "\t\t\tcontinue\n",
    "\t\t# should we get the first sample from the start?\n",
    "\t\toffset = random.randint(0, n - k)\n",
    "\t\tprocessed_dataset = pd.concat([processed_dataset, pair_samples.iloc[offset:k - 1 + offset]])\n",
    "\n",
    "\treturn processed_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80d522c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# balanced_dataset = balance_dataset(dataset, 'route_changed', factor=0.001)\n",
    "# balanced_dataset = cut_dataset(dataset, factor=0.001)\n",
    "# balanced_dataset = cut_pairs(dataset, 0.005)\n",
    "balanced_dataset = trim_excess_data_pairwise(dataset, k=1000)\n",
    "balanced_dataset = balance_dataset(balanced_dataset, 'route_changed', factor=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94e321ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "balanced_dataset.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8c65ef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parses the all_rtts column from string to list\n",
    "def parse_rtts(stringzinha):\n",
    "    try:\n",
    "        return ast.literal_eval(stringzinha)\n",
    "    except:\n",
    "        return []\n",
    "\n",
    "# Calculates mean and std of all_rtts\n",
    "rtt_lists = balanced_dataset[\"all_rtts\"].apply(parse_rtts)\n",
    "balanced_dataset[\"mean_rtt\"] = rtt_lists.apply(lambda x: np.mean(x) if len(x) > 0 else 0.0)\n",
    "balanced_dataset[\"std_rtt\"] = rtt_lists.apply(\n",
    "\tlambda x: np.std(x, ddof=1) if len(x) > 1 else 0.0\n",
    ")\n",
    "\n",
    "# Drops the all_rtts column\n",
    "balanced_dataset = balanced_dataset.drop(columns=['all_rtts'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "977b951e",
   "metadata": {},
   "outputs": [],
   "source": [
    "balanced_dataset['relative_dropped_probes'] = (balanced_dataset['total_probes_sent'] - balanced_dataset['total_replies_last_hop']) / balanced_dataset['total_probes_sent']\n",
    "\n",
    "balanced_dataset = balanced_dataset.drop(columns=['total_replies_last_hop', 'total_probes_sent'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be27334b",
   "metadata": {},
   "outputs": [],
   "source": [
    "balanced_dataset.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43c516cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Contextualize the dataset with a sliding window\n",
    "def contextualize_sliding_window(dataset, window_size=2):\n",
    "\n",
    "    df = dataset.copy()\n",
    "    \n",
    "    for i in range(1, window_size):\n",
    "        # df[f'last_mean_{i}'] = df['mean_rtt'].shift(i)\n",
    "        # df[f'last_std_{i}'] = df['std_rtt'].shift(i)\n",
    "        df[f'diff_sq_mean_{i}'] = (df['mean_rtt'] - df['mean_rtt'].shift(i))**2\n",
    "        df[f'diff_sq_std_{i}'] = (df['std_rtt'] - df['std_rtt'].shift(i))**2\n",
    "\n",
    "    return df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01077eb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "balanced_dataset = contextualize_sliding_window(balanced_dataset, window_size=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "756055b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pearson correlation\n",
    "cor_pearson = balanced_dataset.corr(method='pearson')\n",
    "plt.figure(figsize=(8, 8))\n",
    "sbn.heatmap(cor_pearson, annot=True, cmap='coolwarm')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b38586f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spearman correlation\n",
    "cor_spearman = balanced_dataset.corr('spearman')\n",
    "plt.figure(figsize=(8, 8))\n",
    "sbn.heatmap(cor_spearman, annot=True, cmap='coolwarm')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9594e34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drops some columns\n",
    "balanced_dataset = balanced_dataset.drop(columns=['date_index',           # Check later if we should keep it :)\n",
    "                          \t\t\t\t\t\t  'seconds_since_start',  # the same as above\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t  'relative_dropped_probes'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4b47e4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exports the treated dataset to a csv file\n",
    "balanced_dataset.to_csv(\"treated_train.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
